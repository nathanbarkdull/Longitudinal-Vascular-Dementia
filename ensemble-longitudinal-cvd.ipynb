{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Machine Learning for Alzheimer's Disease Classification and Prediction\n# Author: Nathan Barkdull\n# Smart Medical Information Learning and Evaluation Lab (SMILE)\n# University of Florida\n# 6/20/2021\n########################################################################\n# Updated 7/22/2021 by NB\n\n\"\"\"\nPredicts cardiovascular dementia risk in an eight year longitudinal study, ARIC (Atherosclerosis Risk in Communities Study)\nusing ensemble model.\n\"\"\"\n\n# Ensemble majority vote\n########################################################################\n# Machine Learning for Alzheimer's Disease Classification and Prediction\n# Author: Nathan Barkdull\n# Smart Medical Information Learning and Evaluation Lab (SMILE)\n# University of Florida\n# 6/20/2021\n########################################################################\n# Updated 7/25/2021 by NB\n\n# Imports\nimport numpy             as np\nimport pandas            as pd \nimport matplotlib.pyplot as plt \n\nfrom scipy                   import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing   import StandardScaler\nfrom sklearn.svm             import SVC\nfrom sklearn.ensemble        import RandomForestClassifier\nfrom xgboost                 import XGBClassifier\nfrom sklearn.metrics         import accuracy_score\nfrom sklearn.pipeline        import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics         import classification_report\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.ensemble        import VotingClassifier","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n# Function to remove columns with p value greater than variable pval\ndef pValueElimation(X, y, pval, verbose):\n    numVars = np.shape(X)[1]\n    toRemove = set()\n    \n    # Loop over all combinations of variables, if the p value of pair is greater than pval\n    # mark the second variable for deletion.\n    for i in range(0, numVars):  \n        # Get p value of pair\n        _, p = stats.ttest_ind(X.iloc[np.where(y == 0)[0], i].values, X.iloc[np.where(y == 1)[0], i].values)\n        if verbose == 1:\n            print(\"The p-value of \" + str(X.columns[i]) + \" is: \" + str(p))\n        \n        # If p value too high, add it to the set of indexs to be deleted.\n        if p > pval:\n            toRemove.add(i)\n                \n    # Delete the set of columns identified and return the remainder\n    return X.drop(X.columns[list(toRemove)], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def runVotingModel(pval=0.2):\n\n    # Load data and train-test split\n    df = pd.read_csv('ARIC_CVD_data.csv')\n    X = df.drop(['CVD related dementia'], axis=1).drop(['ID_C'], axis=1)\n    y = df['CVD related dementia']\n    \n\n    # Eliminate features and create train test split\n    X_elim = pValueElimation(X, y, pval, verbose=0)\n    X_train, X_test, y_train, y_test = train_test_split(X_elim, y, test_size = 0.3)\n    \n    print(X_elim.shape)\n    X_elim.describe()\n    \n    # models for majority voting\n    pipe_svc = Pipeline([('scl', StandardScaler()),\n                     ('clf', SVC())])\n\n    param_grid = {'clf__C':[0.1, 1, 10, 100],\n                  'clf__kernel':['rbf','poly','linear','sigmoid'],\n                  'clf__degree':[1,2,3,4],\n                  'clf__gamma': [1, 0.1, 0.01, 0.001]}\n\n    grid1 = GridSearchCV(pipe_svc, param_grid, refit = True, cv=10, verbose = 0)\n\n    pipe_RFC = Pipeline([('scl', StandardScaler()),\n                 ('clf', RandomForestClassifier())])\n\n\n    param_grid = {'clf__bootstrap': [True],\n                  'clf__max_depth': [5, 10, 15],\n                  'clf__max_features': ['auto'],\n                  'clf__min_samples_leaf': [2, 3],\n                  'clf__min_samples_split': [10, 15, 20],\n                  'clf__n_estimators': [800, 1000, 1200,]}\n\n    grid2 = GridSearchCV(pipe_RFC, param_grid, refit = True, cv=10, verbose = 0)\n\n    pipe_XGB = Pipeline([('scl', StandardScaler()),\n                 ('clf', XGBClassifier(learning_rate=0.02, n_estimators=600,))])\n\n    param_grid = {'clf__min_child_weight': [10, 15],\n                  'clf__gamma': [5],\n                  'clf__subsample': [0.6, 0.8, 1.0],\n                  'clf__colsample_bytree': [1.0],\n                  'clf__max_depth': [3, 4, 5]}\n\n    grid3 = GridSearchCV(pipe_XGB, param_grid, refit = True, cv=10, verbose = 0)\n    \n    # Create voting classifier \n    eclf = VotingClassifier(estimators=[('svc', grid1), ('rfc', grid2), ('xgb', grid3)])\n    \n    # Train and test the model\n    eclf.fit(X_train, y_train)\n\n    y_pred = eclf.predict(X_test)\n\n    print(classification_report(y_test, y_pred))\n    print(accuracy_score(y_test, y_pred))\n    \n    return accuracy_score(y_test, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"runVotingModel(pval=0.18)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## P values ## \ndf = pd.read_csv('ARIC_CVD_data.csv')\nX = df.drop(['CVD related dementia'], axis=1).drop(['ID_C'], axis=1)\ny = df['CVD related dementia']\n\npval=0.18\nX_elim = pValueElimation(X, y, pval, verbose=1)\nprint(X_elim.shape)","metadata":{"scrolled":true},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":"The p-value of REXA2A is: 0.008017490690484729\n\nThe p-value of REXA2B is: 0.15680098968701664\n\nThe p-value of REXA3A is: 0.5193096668054968\n\nThe p-value of REXA5A is: 0.8014966505958575\n\nThe p-value of REXA5C is: 0.7023445388529963\n\nThe p-value of REXA6A is: 0.7023445388529963\n\nThe p-value of RIPA2 is: 0.9608360110303903\n\nThe p-value of RIPA3 is: 0.9068096179342491\n\nThe p-value of RIPA4 is: 0.18031258316066984\n\nThe p-value of RIPA5 is: 0.6491058572612669\n\nThe p-value of RIPA6 is: 0.9973767408701945\n\nThe p-value of RIPA7 is: 0.7387017345749816\n\nThe p-value of RIPA8 is: 0.40200498392820516\n\nThe p-value of RIPA9 is: 0.24827493559775216\n\nThe p-value of RIPA10 is: 0.5360664604405619\n\nThe p-value of RIPA11 is: 0.6397856952131997\n\nThe p-value of RIPA12 is: 0.4891013893471361\n\nThe p-value of RIPA13 is: 0.6058435159668298\n\nThe p-value of RIPA14 is: 0.06526631870854448\n\nThe p-value of RIPA15 is: 0.6583419755982314\n\nThe p-value of RIPA16 is: 0.5630652174060875\n\nThe p-value of RIPA17 is: 0.3184613766047082\n\nThe p-value of RIPA20 is: 0.7885764454402839\n\nThe p-value of RIPA21 is: 0.06154294401207952\n\nThe p-value of RIPA22 is: 0.5193716464032622\n\nThe p-value of RIPA23 is: 0.24270797268294417\n\nThe p-value of RIPA24 is: 0.23335699005106042\n\nThe p-value of RIPA25 is: 0.3707699594445847\n\nThe p-value of RIPA26 is: 0.6870877832718945\n\nThe p-value of RIPA27 is: 0.8739458383243301\n\nThe p-value of RIPA28 is: 0.17998904408774855\n\nThe p-value of RIPA29 is: 0.37780641354012656\n\nThe p-value of RIPA30 is: 0.45263225216541425\n\nThe p-value of RIPA31 is: 0.994222014364742\n\nThe p-value of RIPA32 is: 0.7818773008649978\n\nThe p-value of RIPA33 is: 0.15998497217242702\n\nThe p-value of RIPA35 is: 0.793370125001773\n\nThe p-value of RIPA36 is: 0.7921543518094543\n\nThe p-value of RIPA37 is: 0.3865383096769245\n\nThe p-value of RIPA38 is: 0.4418393850876484\n\nThe p-value of RIPA39 is: 0.7667245335061912\n\nThe p-value of RIPA40 is: 0.4836508766324872\n\nThe p-value of RIPA41 is: 0.6922322960790538\n\nThe p-value of RIPA42 is: 0.36694060931510875\n\nThe p-value of RIPA43 is: 0.6143442256403995\n\nThe p-value of RIPA44 is: 0.837267566673484\n\nThe p-value of RIPA45 is: 0.19359393644310277\n\nThe p-value of RIPA46 is: 0.26459093117520804\n\nThe p-value of RIPA47 is: 0.20454643779080547\n\nThe p-value of RIPA48 is: 0.17253499114665968\n\nThe p-value of RIPA49 is: 0.26112132204644667\n\nThe p-value of RIPA50 is: 0.5049826071766352\n\nThe p-value of RIPA51 is: 0.9343722362040227\n\nThe p-value of RIPA52 is: 0.9592127365304883\n\nThe p-value of RIPA53 is: 0.9221673434626991\n\nThe p-value of RIPA54 is: 0.8968875998496946\n\nThe p-value of RIPA55 is: 0.526659676248829\n\nThe p-value of RIPA56 is: 0.5412677628787853\n\nThe p-value of RIPA57 is: 0.42552776276099447\n\nThe p-value of RIPA58 is: 0.6186157881675367\n\nThe p-value of RIPA59 is: 0.8824480122271312\n\nThe p-value of RIPA60 is: 0.981220410616811\n\nThe p-value of RIPA61 is: 0.3184613766047082\n\nThe p-value of RIPA62 is: 0.3184613766047084\n\nThe p-value of RIPA71 is: 0.8093177926484554\n\nThe p-value of RIPA72 is: 0.8224407506142162\n\nThe p-value of RIPA73 is: 0.19367735518059065\n\nThe p-value of RIPA74 is: 0.6076824472963506\n\nThe p-value of RIPA75 is: 0.7563000943547299\n\nThe p-value of RIPA76 is: 0.6180534049751256\n\nThe p-value of RIPA77 is: 0.3023906258353952\n\nThe p-value of RIPA78 is: 0.3467688103797214\n\nThe p-value of RIPA79 is: 0.6235560986872584\n\nThe p-value of RIPA80 is: 0.6464242796911334\n\nThe p-value of RIPA81 is: 0.6034441664010006\n\nThe p-value of RIPA82 is: 0.5856902961057506\n\nThe p-value of RIPA83 is: 0.06770539610228832\n\nThe p-value of RIPA84 is: 0.6867936248701538\n\nThe p-value of RIPA85 is: 0.5630652174060875\n\nThe p-value of RIPA86 is: 0.3184613766047082\n\nThe p-value of RIPX89 is: 0.32485216440697806\n\nThe p-value of RIPX90 is: 0.31174176633227996\n\nThe p-value of RIPX91 is: 0.16631266778703327\n\nThe p-value of RIPX92 is: 0.029206973759932617\n\nThe p-value of RIPA93 is: 0.02515349128206415\n\nThe p-value of RIPA94 is: 0.5294375637791764\n\nThe p-value of RIPA95 is: 0.37711556323109807\n\nThe p-value of RIPA98 is: 0.36298719831432813\n\nThe p-value of RLBA10 is: 0.5823018672222351\n\nThe p-value of RLBA11 is: 0.08679370829053062\n\nThe p-value of RLBA12A is: 0.03622779694862203\n\nThe p-value of RLBA12B is: 0.08732207460710945\n\nThe p-value of RLBA12C is: 0.33389455183448324\n\nThe p-value of RLBA12D is: 0.7722680368051543\n\nThe p-value of RLBA13A is: 0.45366973883770767\n\nThe p-value of RLBA13C is: 0.08178912810185487\n\nThe p-value of RLBA13D is: 0.31498805645908\n\nThe p-value of RLBA14 is: 0.3184613766047083\n\nThe p-value of RLBA15A is: 0.2965030982004766\n\nThe p-value of RLBA15B is: 0.23948716741434473\n\nThe p-value of RLBA15C is: 0.11708826770534204\n\nThe p-value of RLBA15D is: 0.5299433670005499\n\nThe p-value of RLBA16 is: 1.0\n\nThe p-value of RLBA17 is: 0.7705346264602624\n\nThe p-value of RLBA18 is: 0.9629194603129799\n\nThe p-value of RLBA19 is: 0.9635991010395151\n\nThe p-value of RLBA20 is: 0.6764595509974196\n\nThe p-value of RLBA21 is: 0.23649785590039518\n\nThe p-value of RLBA22 is: 0.3928475970244517\n\nThe p-value of RLBA23 is: 0.43730128910654\n\nThe p-value of RLBA24 is: 0.2613418570758759\n\nThe p-value of RLBA25 is: 1.0\n\nThe p-value of RLBA26 is: 0.3184613766047084\n\nThe p-value of RLBA27 is: 0.3184613766047084\n\nThe p-value of RLBA29 is: 0.3184613766047084\n\nThe p-value of RLBA30 is: 0.5477600930433524\n\nThe p-value of RLBA31A is: 0.7654502584717378\n\nThe p-value of RLBA31B is: 0.7654696826917478\n\nThe p-value of RLBA38 is: 0.3184613766047083\n\nThe p-value of RLBA39 is: 0.07612353033114178\n\nThe p-value of RLBA40 is: 0.3184613766047083\n\nThe p-value of RLBA41 is: 1.0\n\nThe p-value of RLBA42 is: 1.0\n\nThe p-value of RLBA43 is: 0.8452396468607033\n\nThe p-value of RLBA44 is: 0.655181760703283\n\nThe p-value of RLBA45 is: 0.3090867903832163\n\nThe p-value of RLBA46 is: 0.2707756087270385\n\nThe p-value of RLBA47 is: 0.14834139520589884\n\nThe p-value of RLBA48 is: 0.41365735150592975\n\nThe p-value of RLBA49 is: 0.563080454595213\n\nThe p-value of RLBA54 is: 0.3184613766047083\n\nThe p-value of RLBA55 is: 0.31498805645908\n\nThe p-value of RLBA57A is: 0.0801335244361924\n\nThe p-value of RLBAFLAG is: 0.6932625005309594\n\nThe p-value of AVN_EYE_31 is: 0.05542948378626096\n\nThe p-value of FOC_EYE_31 is: 0.20712028876535518\n\nThe p-value of RET_HEM_31 is: 0.25093685760516454\n\nThe p-value of FLAM_HEM_31 is: 1.0\n\nThe p-value of BLOT_HEM_31 is: 0.17616128963709168\n\nThe p-value of SOFTEXUD_31 is: 0.6526992861814687\n\nThe p-value of PAPSWELL_31 is: 0.1568009896870165\n\nThe p-value of MICROANY_31 is: 0.030638750405535046\n\nThe p-value of ADV_RTP_31 is: 0.20790798121277168\n\nThe p-value of AV_MABP_31 is: 8.04784330471305e-07\n\nThe p-value of BMI32 is: 0.00137179005847638\n\nThe p-value of ARTSS31 is: 0.43005606644203376\n\nThe p-value of VEINSS31 is: 0.13540935618808667\n\nThe p-value of CRAE_T is: 0.3246217155700538\n\nThe p-value of CRVE is: 0.16631266778703327\n\nThe p-value of CRAE_B is: 0.33251729561357557\n\nThe p-value of AV_T31 is: 0.029554922119978677\n\nThe p-value of AV_B31 is: 0.027965784675204435\n\nThe p-value of CURDRK31 is: 0.07413322845678923\n\nThe p-value of FORDRK31 is: 0.219669374029873\n\nThe p-value of CURSMK31 is: 0.16009417654568103\n\nThe p-value of FORSMK31 is: 0.09721784470184597\n\nThe p-value of V3AGE31 is: 0.49686172730420286\n\nThe p-value of SPRT_I31 is: 0.06349535880803087\n\nThe p-value of DIABTS33 is: 0.011850954110934332\n\nThe p-value of RACEGRP is: 3.235744327736955e-05\n\nThe p-value of GENDER is: 0.8902881147968292\n\nThe p-value of V1AGE01 is: 0.4451324902690049\n\nThe p-value of ELEVEL01 is: 0.036606533918007216\n\nThe p-value of ELEVEL02 is: 0.0398724863582944\n\n(212, 37)\n"}]},{"cell_type":"code","source":"# vascular dem results, svm\nacc = np.array([0.5, 0.609375, 0.5625, 0.640625, 0.609375, 0.65625, 0.625, 0.640625, 0.59375, 0.5625,\n                0.640625, 0.703125, 0.703125, 0.65625, 0.5625, 0.59375, 0.6875, 0.6875, 0.65625, 0.578125,\n                0.640625, 0.625, 0.640625, 0.59375, 0.71875, 0.640625, 0.65625, 0.5625, 0.703125, 0.671875,\n                0.671875, 0.59375, 0.625, 0.59375, 0.453125, 0.59375, 0.578125, 0.578125, 0.5625, 0.578125,\n                0.46875, 0.5625, 0.546875, 0.625, 0.578125, 0.59375, 0.59375, 0.640625, 0.546875, 0.546875])\n\n\nprint(\"Performance of SVM classifier in predicting vascular dem diagnosis\")\nprint(\"pval = 0.05 |  av. accuracy = \" + str(acc[0:10].mean()))\nprint(\"pval = 0.1  |  av. accuracy = \" + str(acc[10:20].mean()))\nprint(\"pval = 0.2  |  av. accuracy = \" + str(acc[20:30].mean()))\nprint(\"pval = 0.4  |  av. accuracy = \" + str(acc[30:40].mean()))\nprint(\"pval = 0.8  |  av. accuracy = \" + str(acc[40:50].mean()))","metadata":{},"execution_count":87,"outputs":[{"name":"stdout","output_type":"stream","text":"Performance of SVM classifier in predicting vascular dem diagnosis\n\npval = 0.05 |  av. accuracy = 0.6\n\npval = 0.1  |  av. accuracy = 0.646875\n\npval = 0.2  |  av. accuracy = 0.6453125\n\npval = 0.4  |  av. accuracy = 0.5828125\n\npval = 0.8  |  av. accuracy = 0.5703125\n"}]},{"cell_type":"code","source":"# vascular dem results, xbg\nacc = np.array([0.625, 0.671875, 0.640625, 0.5625, 0.59375, 0.5625, 0.515625, 0.546875, 0.578125, 0.671875,\n                0.5625, 0.5625, 0.640625, 0.625, 0.640625, 0.5625, 0.625, 0.6875, 0.625, 0.640625,\n                0.6875, 0.59375, 0.46875, 0.75, 0.625, 0.640625, 0.703125, 0.6875, 0.65625, 0.546875,\n                0.625, 0.625, 0.59375, 0.65625, 0.53125, 0.625, 0.546875, 0.65625, 0.65625, 0.546875,\n                0.5625, 0.640625, 0.578125, 0.5625, 0.625, 0.5625, 0.5625, 0.578125, 0.65625, 0.640625])\n\nprint(\"Performance of XBG classifier in predicting vascular dem diagnosis\")\nprint(\"pval = 0.05 |  av. accuracy = \" + str(acc[0:10].mean()))\nprint(\"pval = 0.1  |  av. accuracy = \" + str(acc[10:20].mean()))\nprint(\"pval = 0.2  |  av. accuracy = \" + str(acc[20:30].mean()))\nprint(\"pval = 0.4  |  av. accuracy = \" + str(acc[30:40].mean()))\nprint(\"pval = 0.8  |  av. accuracy = \" + str(acc[40:50].mean()))","metadata":{},"execution_count":88,"outputs":[{"name":"stdout","output_type":"stream","text":"Performance of XBG classifier in predicting vascular dem diagnosis\n\npval = 0.05 |  av. accuracy = 0.596875\n\npval = 0.1  |  av. accuracy = 0.6171875\n\npval = 0.2  |  av. accuracy = 0.6359375\n\npval = 0.4  |  av. accuracy = 0.60625\n\npval = 0.8  |  av. accuracy = 0.596875\n"}]}]}